{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6eb10ebc",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b92db13317f0e6015961bb08b3e82abe",
     "grade": false,
     "grade_id": "cell-5cf52405126f2776",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Python File Objects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde64ab9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a387926e4abf68d9b2700ae2a55753ff",
     "grade": false,
     "grade_id": "cell-c7eab4c0d23e582f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Instructions\n",
    "\n",
    "* Complete the programming exercises below.\n",
    "* Delete or comment out the line of code in each cell which says `raise NotImplementedError()` and replace it with your own.\n",
    "\n",
    "### Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d585affc",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5883ccb9de705b4500eda96036feedf3",
     "grade": false,
     "grade_id": "cell-e901448fcdc0d1d8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Path to file or directory\n",
    "\n",
    "Sometimes you want to work with files in a particular directory. In order to do that you need to get the path. There are a couple different ways you can do that.\n",
    "\n",
    "In Windows you can open a command prompt (in Mac a terminal window) and drag the file or folder to the command prompt and the path will display in the window. You can then copy the path and paste it into your code. It will probably look something like this.\n",
    "\n",
    "`C:\\Users\\UserName\\Documents`\n",
    "\n",
    "To use the path in your code, you will want to assign it to a variable.\n",
    "\n",
    "`file_path = 'C:\\Users\\UserName\\Documents'`\n",
    "\n",
    "Windows users will quickly realize that their path as Windows formats it causes error when used without some modification. (Mac users won't have this problem because Macs format the path in a way that Python can use it without modification.) This is a problem for Windows users because Windows uses backslash (\\) characters in the file path. In Python, the backslash character is a special character. To use special characters in strings in Python, they need to have an escape character added before the special character. In Python, the escape character is the backslash (\\). One option Windows users have is to add an extra backslash in front of every backslash in the path. It will look like this.\n",
    "\n",
    "`file_path = 'C:\\\\Users\\\\UserName\\\\Documents'`\n",
    "\n",
    "Another option is to change each backslash (\\) to a forward slash (/).\n",
    "\n",
    "`file_path = 'C:/Users/UserName/Documents'`\n",
    "\n",
    "Another option is to format the string as a raw string. This option saves a lot of typing. This is done in Python by adding a lowercase `r` in front of the quotation marks for the string. This is a signal to Python to treat the string exactly as it is formatted and consider any special characters included in the string as literal characters.\n",
    "\n",
    "`file_path = r'C:\\Users\\UserName\\Documents'`\n",
    "\n",
    "Another option is to use a graphical user interface included in Python (called tkinter) to open a dialog window and allow the user to select the file or directory of interest. Run the code block below to use the file dialog to select the files directory included in the repository for this assignment. (Be sure to select the inner files directory which actually contains the files needed for the assignment.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cbe2b94",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "feca7292f76a7194a482af7131a209a0",
     "grade": false,
     "grade_id": "cell-183af8e202482f24",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening dialogue box for folder selection. Please choose a folder.\n",
      "Folder selected:\n",
      "C:/Users/u0536877/Downloads/exerPythCombineFiles-master (1)/exerPythCombineFiles-master/.ipynb_checkpoints\n"
     ]
    }
   ],
   "source": [
    "# Have user select the folder with the needed files.\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "\n",
    "root = tk.Tk()\n",
    "root.lift()\n",
    "root.withdraw()\n",
    "\n",
    "# This code block will open a specific file. (Uncomment the lines after this comment to use them.)\n",
    "#print('Opening dialogue box for file selection. Please choose a file.')\n",
    "#file_path = filedialog.askopenfilename()\n",
    "#print('File selected:')\n",
    "\n",
    "# This code block will get a directory path. (Uncomment the lines after this comment to use them.)\n",
    "print('Opening dialogue box for folder selection. Please choose a folder.')\n",
    "file_path = filedialog.askdirectory()\n",
    "print('Folder selected:')\n",
    "\n",
    "print(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25e136f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "53909d360d9af048066cffc30634b1a6",
     "grade": false,
     "grade_id": "cell-d16626c0c6bbe05e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Working with different file types in Python\n",
    "\n",
    "The purpose of this assignment is to see how to work with different file types in Python. Run the code block below to see the different types of files included in the folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d79836bd",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1b4b1b7e9b0f816a028b9aa9ecbb3e56",
     "grade": false,
     "grade_id": "cell-63ec098105c6360f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files in folder:  [] \n",
      "\n",
      "CSV files:  [] \n",
      "Excel files:  [] \n",
      "JSON files:  [] \n",
      "XML files:  []\n"
     ]
    }
   ],
   "source": [
    "# Make sure correct files are recognized.\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# List the files in the directory.\n",
    "files = os.listdir(file_path)\n",
    "print('All files in folder: ', files, '\\n')\n",
    "\n",
    "# List of file types we want to add\n",
    "file_types = ['xlsx','csv','json','xml']\n",
    "\n",
    "# create a list of files for each file type\n",
    "files_csv = [f for f in files if f[-3:] == 'csv']\n",
    "files_xlsx = [f for f in files if f[-4:] == 'xlsx']\n",
    "files_json = [f for f in files if f[-4:] == 'json']\n",
    "files_xml = [f for f in files if f[-3:] == 'xml']\n",
    "\n",
    "print('CSV files: ', files_csv, '\\nExcel files: ', files_xlsx, '\\nJSON files: ',files_json, '\\nXML files: ', files_xml)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ecb133",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "036cbdaf3fccb0cf6e64a982dc89dd48",
     "grade": false,
     "grade_id": "cell-a6b8c71f6b3c4122",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Write you answers as comments in the cell below.\n",
    "\n",
    "* What types of files are included in the folder? List the file extensions and how many of each type you see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b231323f",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "411e33553ef624d8113dc68030dcd2e7",
     "grade": true,
     "grade_id": "cell-2e7557a700ca381e",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV, Excel, JSON, XML. I see only one of each type\n"
     ]
    }
   ],
   "source": [
    "print (\"CSV, Excel, JSON, XML. I see only one of each type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39c2827",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "616728e37e1fc6e8975a812b35ba637d",
     "grade": false,
     "grade_id": "cell-49ef237b3b87c9ef",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Creating a Pandas dataframe\n",
    "\n",
    "Run the code block below to read each data file and combine them into a Pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe8ee1d1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "63101f07169f46ab9e272e861b050aff",
     "grade": false,
     "grade_id": "cell-777c52aa20d58ca8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import requests \n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# Iterate through the files in the directory and append each one into the dataframe.\n",
    "# This will only work correctly if the files have the exact same column names.\n",
    "df_list = []\n",
    "for f in files_csv:\n",
    "    data = pd.read_csv(str(file_path) + '/' + str(f), index_col=None, header=0)\n",
    "    data['Source'] = f\n",
    "    df_list.append(data)\n",
    "    \n",
    "for f in files_xlsx:\n",
    "    data = pd.read_excel(str(file_path) + '/' + str(f))\n",
    "    data['Source'] = f\n",
    "    df_list.append(data)\n",
    "    \n",
    "# Iterate through the json files and add data from each to a list.\n",
    "json_list = []\n",
    "for f in files_json:\n",
    "    with open(str(file_path) + '/' + str(f)) as json_file:\n",
    "        json_obj = json.load(json_file)\n",
    "        json_obj['Source'] = f\n",
    "        json_list.append(json_obj.copy())\n",
    "# Turn the combined list into a dataframe.\n",
    "data = pd.DataFrame(json_list)\n",
    "# Add the data frame to the list of dataframes.\n",
    "df_list.append(data)\n",
    "    \n",
    "# Iterate through the xml files and add data from each to a list.\n",
    "xml_list = []\n",
    "for f in files_xml:\n",
    "    # create element tree object \n",
    "    tree = ET.parse(str(file_path) + '/' + str(f))\n",
    "    # get root element \n",
    "    root = tree.getroot()\n",
    "    # create dictionary from XML tags and values\n",
    "    itemdict = {}\n",
    "    for item in root:\n",
    "        itemdict[item.tag] = item.text\n",
    "    itemdict['Source'] = f\n",
    "    xml_list.append(itemdict.copy())\n",
    "# Turn the combined list into a dataframe.\n",
    "data = pd.DataFrame(xml_list)\n",
    "# Add the data frame to the list of dataframes.\n",
    "df_list.append(data)\n",
    "\n",
    "# Combine all the data frames in the list into a single data frame.    \n",
    "df =  pd.concat(df_list, axis=0, ignore_index=True, sort=False)\n",
    "\n",
    "# See how many rows the data frame has.\n",
    "print(len(df.index))\n",
    "\n",
    "# Show the data in the data frame.\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bcfaa3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5ffe1ee85e9a932d57ef6708d9ad2780",
     "grade": false,
     "grade_id": "cell-fc20f8a537557818",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Saving a dataframe to csv\n",
    "\n",
    "Run the code block below to save your new dataframe as a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e3e5a7d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d63ff84c0c6a7b1c4499c1320a82db65",
     "grade": false,
     "grade_id": "cell-8f820404d1d343ed",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-25\n",
      "C:/Users/u0536877/Downloads/exerPythCombineFiles-master (1)/exerPythCombineFiles-master/.ipynb_checkpoints/NewCombinedFile_2022-10-25.csv\n",
      "File saved.\n"
     ]
    }
   ],
   "source": [
    "# Save the dataframe to a new combined csv file.\n",
    "\n",
    "# Add today's date to the name of the new file.\n",
    "from datetime import date\n",
    "today = date.today()\n",
    "print(today)\n",
    "\n",
    "filename = str(file_path) + '/' + 'NewCombinedFile_' + str(today) + '.csv'\n",
    "print(filename)\n",
    "\n",
    "df.to_csv(filename, index=False)\n",
    "print('File saved.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b2f34c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5caccc71a46288d22884f19f41ba45a2",
     "grade": false,
     "grade_id": "cell-ffeacc8e7cac213c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Create additional data files\n",
    "\n",
    "Create a new data file for each type included in the folder. (You can use Excel to modify the content in the .xlsx and .csv files and save them under a new name in the same folder. You can use VSCode or Notepad++ to modify the content of an .xml and .json file and save those under a new name in the same folder.) Make sure you create at least one additional file for each type of data file in the folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607b9aa6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "85db0e5d334b3bfe20b64a4ec1e4c372",
     "grade": false,
     "grade_id": "cell-e54523c23d0f01c1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Enter code in the cell below.\n",
    "\n",
    "* Create a variable called `file_path` which contains the path to the folder where all the data files are included. You can use any of the methods described at the beginning of the notebook (Manually copy the path or copy the code to create a file dialog to choose the correct folder.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2fa0776",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "361e07929d306cd9e8fa4c5ae3709b63",
     "grade": true,
     "grade_id": "cell-9e46a40a2a029afd",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening dialogue box for file selection. Please choose a file.\n",
      "File selected:\n",
      "Opening dialogue box for folder selection. Please choose a folder.\n",
      "Folder selected:\n",
      "C:/Users/u0536877/Downloads/exerPythCombineFiles-master (1)/exerPythCombineFiles-master/.ipynb_checkpoints\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "\n",
    "root = tk.Tk()\n",
    "root.lift()\n",
    "root.withdraw()\n",
    "\n",
    "print('Opening dialogue box for file selection. Please choose a file.')\n",
    "file_path = filedialog.askopenfilename()\n",
    "print('File selected:')\n",
    "\n",
    "# This code block will get a directory path. (Uncomment the lines after this comment to use them.)\n",
    "print('Opening dialogue box for folder selection. Please choose a folder.')\n",
    "file_path = filedialog.askdirectory()\n",
    "print('Folder selected:')\n",
    "\n",
    "print(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4386fdd2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0ae36a589a1d7966b8ab3678102011b5",
     "grade": false,
     "grade_id": "cell-be96adc4fbda881b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Enter code in the cell below.\n",
    "\n",
    "* Add code in the cell below to list the files in the folder and create lists for each data file type. (Hint - It's OK to reuse code from earlier in the assignment.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a650faed",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4510ca612c9ad4a08f90022eeb4db8fa",
     "grade": true,
     "grade_id": "cell-53ce4edf792e3627",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files in folder:  ['NewCombinedFile_2022-10-25.csv', 'Python_CombineFiles New Assignment-checkpoint.ipynb'] \n",
      "\n",
      "CSV files:  ['NewCombinedFile_2022-10-25.csv'] \n",
      "Excel files:  [] \n",
      "JSON files:  [] \n",
      "XML files:  []\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# List the files in the directory.\n",
    "files = os.listdir(file_path)\n",
    "print('All files in folder: ', files, '\\n')\n",
    "\n",
    "# List of file types we want to add\n",
    "file_types = ['xlsx','csv','json','xml']\n",
    "\n",
    "# create a list of files for each file type\n",
    "files_csv = [f for f in files if f[-3:] == 'csv']\n",
    "files_xlsx = [f for f in files if f[-4:] == 'xlsx']\n",
    "files_json = [f for f in files if f[-4:] == 'json']\n",
    "files_xml = [f for f in files if f[-3:] == 'xml']\n",
    "\n",
    "print('CSV files: ', files_csv, '\\nExcel files: ', files_xlsx, '\\nJSON files: ',files_json, '\\nXML files: ', files_xml)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56b6eda",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3e299951d3b6ac2081e24406a31a7bbf",
     "grade": false,
     "grade_id": "cell-9046144d63ad9faf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Write you answers as comments in the cell below.\n",
    "\n",
    "* What types of files are included in the folder? List the file extensions and how many of each type you see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e93c2e7b",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2e46c44126e2c3d6d31e4f855cca05c1",
     "grade": true,
     "grade_id": "cell-b396c8c422e37b42",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV files are included in the folder. File extension New combined file. Only see one type\n"
     ]
    }
   ],
   "source": [
    "print(\"CSV files are included in the folder. File extension New combined file. Only see one type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32084d2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ceae4851ebc21a84a51f27ed084ea1d8",
     "grade": false,
     "grade_id": "cell-ac79fbd19d488577",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Enter code in the cell below.\n",
    "\n",
    "* Add code in the cell below to read each data file and combine them into a Pandas dataframe and display the dataframe. (Hint - It's OK to reuse code from earlier in the assignment.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de01933e",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8a1dbfe4b4958235b306d12cf4d59785",
     "grade": true,
     "grade_id": "cell-c2d07cf21cd676a1",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "EmptyDataError",
     "evalue": "No columns to parse from file",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEmptyDataError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m df_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m files_csv:\n\u001b[1;32m----> 9\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSource\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m f\n\u001b[0;32m     11\u001b[0m     df_list\u001b[38;5;241m.\u001b[39mappend(data)\n",
      "File \u001b[1;32m~\\Anaconda3\\New folder\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\Anaconda3\\New folder\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    666\u001b[0m     dialect,\n\u001b[0;32m    667\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    677\u001b[0m )\n\u001b[0;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\New folder\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\Anaconda3\\New folder\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    932\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\New folder\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1235\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1232\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1234\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1235\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mapping[engine](f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions)\n\u001b[0;32m   1236\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1237\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\Anaconda3\\New folder\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:75\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     72\u001b[0m     kwds\u001b[38;5;241m.\u001b[39mpop(key, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     74\u001b[0m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m ensure_dtype_objs(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m---> 75\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader \u001b[38;5;241m=\u001b[39m parsers\u001b[38;5;241m.\u001b[39mTextReader(src, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munnamed_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39munnamed_cols\n\u001b[0;32m     79\u001b[0m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\New folder\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:551\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mEmptyDataError\u001b[0m: No columns to parse from file"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests \n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# Iterate through the files in the directory and append each one into the dataframe.\n",
    "# This will only work correctly if the files have the exact same column names.\n",
    "df_list = []\n",
    "for f in files_csv:\n",
    "    data = pd.read_csv(str(file_path) + '/' + str(f), index_col=None, header=0)\n",
    "    data['Source'] = f\n",
    "    df_list.append(data)\n",
    "    \n",
    "for f in files_xlsx:\n",
    "    data = pd.read_excel(str(file_path) + '/' + str(f))\n",
    "    data['Source'] = f\n",
    "    df_list.append(data)\n",
    "    \n",
    "# Iterate through the json files and add data from each to a list.\n",
    "json_list = []\n",
    "for f in files_json:\n",
    "    with open(str(file_path) + '/' + str(f)) as json_file:\n",
    "        json_obj = json.load(json_file)\n",
    "        json_obj['Source'] = f\n",
    "        json_list.append(json_obj.copy())\n",
    "# Turn the combined list into a dataframe.\n",
    "data = pd.DataFrame(json_list)\n",
    "# Add the data frame to the list of dataframes.\n",
    "df_list.append(data)\n",
    "    \n",
    "# Iterate through the xml files and add data from each to a list.\n",
    "xml_list = []\n",
    "for f in files_xml:\n",
    "    # create element tree object \n",
    "    tree = ET.parse(str(file_path) + '/' + str(f))\n",
    "    # get root element \n",
    "    root = tree.getroot()\n",
    "    # create dictionary from XML tags and values\n",
    "    itemdict = {}\n",
    "    for item in root:\n",
    "        itemdict[item.tag] = item.text\n",
    "    itemdict['Source'] = f\n",
    "    xml_list.append(itemdict.copy())\n",
    "# Turn the combined list into a dataframe.\n",
    "data = pd.DataFrame(xml_list)\n",
    "# Add the data frame to the list of dataframes.\n",
    "df_list.append(data)\n",
    "\n",
    "# Combine all the data frames in the list into a single data frame.    \n",
    "df =  pd.concat(df_list, axis=0, ignore_index=True, sort=False)\n",
    "\n",
    "# See how many rows the data frame has.\n",
    "print(len(df.index))\n",
    "\n",
    "# Show the data in the data frame.\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6328c230",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d8069c1c76676e7fb2473f9734d61085",
     "grade": false,
     "grade_id": "cell-1f9b56443ee0fe56",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Enter code in the cell below.\n",
    "\n",
    "* Add code in the cell below to save your new dataframe as a csv file. (Hint - It's OK to reuse code from earlier in the assignment.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9166a0c",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f2e3edce85e2bec2716893357ff5dcce",
     "grade": true,
     "grade_id": "cell-737b71ac218cd8c8",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-25\n",
      "C:/Users/u0536877/Downloads/exerPythCombineFiles-master (1)/exerPythCombineFiles-master/.ipynb_checkpoints/NewCombinedFile_2022-10-25.csv\n",
      "File saved.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from datetime import date\n",
    "today = date.today()\n",
    "print(today)\n",
    "\n",
    "filename = str(file_path) + '/' + 'NewCombinedFile_' + str(today) + '.csv'\n",
    "print(filename)\n",
    "\n",
    "df.to_csv(filename, index=False)\n",
    "print('File saved.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
